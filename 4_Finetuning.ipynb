{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finetuning Torchvision Models\n",
    "=============================\n",
    "\n",
    "Author: Wataru Uegami, MD\n",
    "\n",
    "2021/3/27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function \n",
    "from __future__ import division\n",
    "import torch\n",
    "from torchvision.models import resnet\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "\n",
    "from mocotools import mocoutil\n",
    "\n",
    "import pandas as pd\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "\n",
    "model_name = \"resnet\"\n",
    "batch_size = 64\n",
    "num_epochs = 150\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model, \n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.5x model\n",
    "We call \"2x\" instead of \"2.5x\" in following code.\n",
    "\n",
    "Execute only when fine-tune 2.5x model. (Skip for 5x and 20x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top level data directory. Here we assume the format of the directory conforms \n",
    "#   to the ImageFolder structure\n",
    "data_dir = Path('path/to/tiles/2x')\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 4\n",
    "\n",
    "# Load pretrained CNN feature extractor\n",
    "checkpoint = torch.load('/path/to/checkpoints/2x_epoch200.pth')\n",
    "\n",
    "cluster = pd.read_csv('/path/to/cluster_results/mgn2x.csv', index_col=0)\n",
    "models_out = '/path/to/finalmodel_Mar10/2x/'\n",
    "\n",
    "def remap(col):\n",
    "    if col in {0,3, 4, 7, 14, 19, 22, 26, 27, 29}:\n",
    "        return 'NearNormal'\n",
    "    elif col in {2, 13,15,16,24, 25, 28}:\n",
    "        return 'CellularTissue'\n",
    "    elif col in {1, 5, 8, 10, 12, 18}:\n",
    "        return 'AcellularFibroticIP'\n",
    "    elif col in {11, 17, 20}:\n",
    "        return 'Exclude'\n",
    "    elif col in {6, 9, 21, 23}:\n",
    "        return 'Other'\n",
    "    \n",
    "cluster['feat'] = cluster['k30'].apply(remap)\n",
    "\n",
    "n_train = 13000\n",
    "\n",
    "minority = 'CellularTissue'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5x\n",
    "\n",
    "Execute only when fine-tune 5x model (skip for 2.5x and 20x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Top level data directory. Here we assume the format of the directory conforms \n",
    "#   to the ImageFolder structure\n",
    "data_dir = Path('path/to/tiles/5x')\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 8\n",
    "\n",
    "# Load pretrained CNN feature extractor\n",
    "checkpoint = torch.load('/path/to/checkpoints/5x_epoch160.pth')\n",
    "\n",
    "cluster5x = pd.read_csv('/path/to/cluster_results/mgn5x.csv', index_col=0)\n",
    "models_out = '/path/to/finalmodel_Mar10/5x/'\n",
    "\n",
    "# Need to define how to integrate the cluster referring the montage\n",
    "def remap(col):\n",
    "    if col in {16, 28, 61}:\n",
    "        return 'LymphoidFollicle'\n",
    "    \n",
    "    elif col in {0, 2, 5, 6, 7, 12, 26, 30, 32,37, 42, 45, 46, 51, 57, 58, 64}:\n",
    "        return 'CellularIP_NSIP'\n",
    "    \n",
    "    elif col in {9, 10, 38, 43, 44,49, 56, 60, 74, 78, 79}:\n",
    "        return 'CellularFibroticIP'\n",
    "    \n",
    "    elif col in {8, 13, 15, 19, 24, 39, 54, 67}:\n",
    "        return 'CompleteNormal'\n",
    "    \n",
    "    elif col in {11, 21, 22, 23, 27, 33, 36, 41, 47, 48, 55, 59, 65, 66, 69, 71,72,73,76}:\n",
    "        return 'Exclude'\n",
    "    \n",
    "    elif col in {4, 14, 17, 18, 50, 53, 68, 77}:\n",
    "        return 'Accellular_fibrosis'\n",
    "    \n",
    "    elif col in {1, 35, 63, 75}:\n",
    "        return 'edge'\n",
    "    \n",
    "    elif col in {20, 34, 52, 62}:\n",
    "        return 'pale'\n",
    "    \n",
    "    else: # 3, 25, 29, 31, 40, 70\n",
    "        return 'Other'\n",
    "    \n",
    "   \n",
    "cluster5x['feat'] = cluster5x['k80'].apply(remap)\n",
    "\n",
    "cluster = cluster5x\n",
    "\n",
    "n_train = 2000\n",
    "\n",
    "minority = 'LymphoidFollicle'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20x\n",
    "In 20x, the cluster and images are already reclassified manually. As the number of each classes are different, here we"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import glob\n",
    "\n",
    "data_dir = Path('/path/to/tiles/20x')\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 8\n",
    "\n",
    "# Load pretrained CNN feature extractor\n",
    "checkpoint = torch.load('/path/to/checkpoints/20x_epoch200.pth')\n",
    "\n",
    "cluster20x = pd.read_csv('/path/to/cluster_results/mgn20x_2.csv', index_col=0)\n",
    "\n",
    "models_out = '/path/to/finalmodel_Mar10/mgn20x_4/'\n",
    "\n",
    "features = ['DF_true', 'elastosis', 'fat', 'Immature_fibroblasts',\n",
    "            'lymphocyte_dense', 'resp_epithelium', 'mucos', 'other']\n",
    "\n",
    "for feat in features:\n",
    "    \n",
    "    print(f'Copy files: {feat}')\n",
    "    imgs = glob.glob('/path/to/train20x_4000each/' + feat + '/*.jpeg') \n",
    "    \n",
    "    num_cases = 4000\n",
    "    num_train = 3500\n",
    "        \n",
    "    random.shuffle(imgs)\n",
    "    \n",
    "    os.makedirs(f'/path/to/finetune_Mar10/20x/train/{feat}', exist_ok=True)\n",
    "    os.makedirs(f'/path/to/finetune_Mar10/20x/val/{feat}', exist_ok=True)\n",
    "    \n",
    "    for i, img in tqdm(enumerate(imgs), total = num_cases):\n",
    "        if i< num_train:\n",
    "            shutil.copy(img, f'/path/to/finetune_Mar10/20x/train/{feat}/')\n",
    "        else:\n",
    "            shutil.copy(img, f'path/to/finetune_Mar10/20x/val/{feat}/')\n",
    "        \n",
    "        if i == num_cases:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inputs\n",
    "------\n",
    "\n",
    "`data dir` have to be define like this:\n",
    "\n",
    "```\n",
    "data_dir\n",
    " |- train\n",
    "     |- cls0\n",
    "         |- 0_1.jpeg\n",
    "         |- 0_2.jpeg\n",
    "         ...\n",
    "     |- cls1\n",
    "     |- cls3\n",
    "     ....\n",
    " |- val\n",
    "     |- cls0\n",
    "         |- 0_1.jpeg\n",
    "         |- 0_2.jpeg\n",
    "         ...\n",
    "     |- cls1\n",
    "     |- cls3\n",
    "     ....\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "for feat in pd.unique(cluster['feat']):\n",
    "    if feat == 'Exclude':\n",
    "        continue\n",
    "    print(feat)\n",
    "    _df = cluster[cluster['feat'] == feat]\n",
    "    \n",
    "\n",
    "    df_downsample = _df.sample(n_shortest)\n",
    "    df_downsample['train'] = [i<n_train for i in df_downsample.reset_index().index]\n",
    "\n",
    "    \n",
    "    path = df_downsample['path']\n",
    "    feat = df_downsample['feat']\n",
    "    train = df_downsample['train']\n",
    "    \n",
    "    for p, f, t in tqdm(zip(path, feat, train)):\n",
    "        p = Path(p)\n",
    "        if t:\n",
    "            t = 'train'\n",
    "        else:\n",
    "            t = 'val'\n",
    "            \n",
    "        p = Path(p)\n",
    "        case_name = p.parent.name\n",
    "        \n",
    "        dst = data_dir.joinpath(t).joinpath(f).joinpath(case_name + p.name)\n",
    "        os.makedirs(dst.parent, exist_ok=True)\n",
    "        \n",
    "        shutil.copy(p, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2,
     24,
     51,
     75
    ]
   },
   "outputs": [],
   "source": [
    "model = mocoutil.ModelMoCo(dim=128, K=4096,m=0.99,T=0.1,arch='resnet18').cuda()\n",
    "\n",
    "print(model.load_state_dict(checkpoint['state_dict']))\n",
    "\n",
    "model = model.encoder_q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions\n",
    "----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     14,
     31,
     62,
     65
    ]
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    if is_inception and phase == 'train':\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            if (epoch==1) | (epoch % 2 == 0):\n",
    "                torch.save({'epoch': epoch, 'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict(),},\n",
    "                           f'{models_out}/ep{str(epoch)}.pth')\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model, val_acc_history\n",
    "\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize and Reshape the Networks\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "snet = []\n",
    "for name, module in model.net.named_children():\n",
    "    snet.append(module)\n",
    "    if isinstance(module, nn.AdaptiveAvgPool2d):\n",
    "        snet.append(nn.Flatten(1))\n",
    "        snet.append(nn.Linear(512, num_classes))\n",
    "        break\n",
    "model.net = nn.Sequential(*snet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.85, 0.7, 0.78], std=[0.15, 0.24, 0.2])\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomApply([\n",
    "            transforms.ColorJitter(brightness=0.08, # 0.4\n",
    "                                   contrast=0.2, # 0.4\n",
    "                                   saturation=0.7,\n",
    "                                   hue=0.03)  # not strengthened  # 0.1\n",
    "        ], p=1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.85, 0.7, 0.78], std=[0.15, 0.24, 0.2])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.85, 0.7, 0.78], std=[0.15, 0.24, 0.2])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "image_datasets['train'].class_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Optimizer\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Send the model to GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are \n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(params_to_update, lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Training and Validation\n",
    "--------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model, hist = train_model(model, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
