{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function \n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, test\n",
    "from torchvision.models import resnet\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "from mocotools.mocoutil import ModelBase, ModelMoCo, test, ImageFolderWithPaths\n",
    "\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the number of classes (findings) for each magnification here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "img_size = 224\n",
    "\n",
    "num_classes = {'mgn2x': 4, 'mgn5x': 8, 'mgn20x': 8, 'mgn20x_4': 8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     25,
     49,
     57,
     66
    ]
   },
   "outputs": [],
   "source": [
    "model = ModelMoCo(\n",
    "        dim=128,\n",
    "        K=4096,\n",
    "        m=0.99,\n",
    "        T=0.1,\n",
    "        arch='resnet18').encoder_q\n",
    "\n",
    "\n",
    "def get_device(use_gpu):\n",
    "    if use_gpu and torch.cuda.is_available():\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        return torch.device(\"cuda\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "    \n",
    "device = get_device(use_gpu=True)\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.85, 0.7, 0.78], std=[0.15, 0.24, 0.2])\n",
    "transform = transforms.Compose([\n",
    "    transforms.CenterCrop(img_size),\n",
    "    transforms.ToTensor(),\n",
    "    normalize])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to classify the findings for each tile, and output as csv file.\n",
    "\n",
    "Model for each magnification have to be identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "data_out_dir = Path('/path/to/my/output/') # location of csv export\n",
    "\n",
    "def featextract(case_dir, model):\n",
    "    mgn_dir = {\n",
    "        'mgn2x' :  '2.5',\n",
    "        'mgn5x' :  '5.0',\n",
    "        'mgn20x_4': '20.0',\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # skip if the tiling is not completed\n",
    "    if False:\n",
    "        completefile = Path(case_dir).name.replace('_files', '.dzi')\n",
    "        if not os.path.exists(Path(case_dir).parent.joinpath(completefile)):\n",
    "            return None\n",
    "        \n",
    "    print(f'------------ {Path(case_dir).name}  ------------')\n",
    "    \n",
    "    for mgn in ['mgn2x', 'mgn5x', 'mgn20x_4']:\n",
    "        \n",
    "        if mgn == 'mgn2x':\n",
    "            cp = '/path/to/mgn2x-cnn-model.pth'\n",
    "        elif mgn == 'mgn5x':\n",
    "            cp = '/path/to/mgn5x-cnn-model.pth'\n",
    "        elif mgn == 'mgn20x_4':\n",
    "            cp = '/path/to/mgn20x-cnn-model.pth'\n",
    "        \n",
    "        cp = Path(cp)\n",
    "        epoch = cp.stem\n",
    "\n",
    "        case_name_tmp = f'{Path(case_dir).name}_{mgn}_{epoch}.csv'\n",
    "        if os.path.exists(Path(data_out_dir).joinpath(case_name_tmp)):\n",
    "            print(f'The result files already exist: {case_name_tmp}')\n",
    "            continue        \n",
    "\n",
    "        print(f'{mgn=}, {epoch=}')\n",
    "        #print('moving files')\n",
    "\n",
    "        img_files = str(Path(case_dir).joinpath(mgn_dir[mgn]))\n",
    "\n",
    "        os.makedirs(f'{img_files}/squarefiles', exist_ok=True)\n",
    "        for img in glob.glob(f'{img_files}/*.jpeg'):\n",
    "            im = Image.open(img)\n",
    "            if im.height == im.width:\n",
    "                shutil.move(img, Path(img).parent.joinpath('squarefiles').joinpath(Path(img).name))\n",
    "\n",
    "        # Build a network\n",
    "        snet = []\n",
    "        for name, module in model.net.named_children():\n",
    "            snet.append(module)\n",
    "            if isinstance(module, nn.AdaptiveAvgPool2d):\n",
    "                snet.append(nn.Flatten(1))\n",
    "                snet.append(nn.Linear(512, num_classes[mgn]))\n",
    "                break\n",
    "        model.net = nn.Sequential(*snet)\n",
    "        model = model.cuda()\n",
    "\n",
    "        # Load checkpoint\n",
    "        cp_loaded = torch.load(cp)\n",
    "\n",
    "        # match checkpoints to the models\n",
    "        model.load_state_dict(cp_loaded['state_dict'])\n",
    "\n",
    "        # forwards\n",
    "        try:\n",
    "            dataset = ImageFolderWithPaths(img_files, transform = transform)\n",
    "        except RuntimeError:\n",
    "            print('Dataset was not enough to extract features')\n",
    "            continue\n",
    "\n",
    "        data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=16, pin_memory=True)\n",
    "        feat, path = test(model, data_loader)\n",
    "        cls_predict = torch.max(feat,1).indices.to('cpu').numpy()\n",
    "\n",
    "        slide = [Path(p).parent.parent.parent.name for p in path]\n",
    "        case = [s.split('_')[0] + '_' + s.split('_')[1] for s in slide]\n",
    "        x = [Path(p).stem.split('_')[-2] for p in path]\n",
    "        y = [Path(p).stem.split('_')[-1] for p in path]\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            'path': path,\n",
    "            'predict': cls_predict,\n",
    "            'case': case,\n",
    "            'slide': slide,\n",
    "            'x': x,\n",
    "            'y': y\n",
    "        })\n",
    "        df.to_csv(Path(data_out_dir).joinpath(f'{slide[0]}_{mgn}_{epoch.zfill(3)}.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# run\n",
    "tile_dir = Path('/path/to/my/tiles/')\n",
    "cases1 = list(tile_dir.glob('*_files'))\n",
    "\n",
    "for c in cases1:\n",
    "    featextract(c, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping the findings\n",
    "\n",
    "Note that the filename of each tiles are: `<x coord>_<y coord>.jpeg`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define helper function here --- \n",
    "\n",
    "def get_img_shape(pos_cls):\n",
    "    pos = list(pos_cls.keys())\n",
    "    x_max = max([x[0] for x in pos])\n",
    "    y_max = max([y[1] for y in pos])\n",
    "    return x_max, y_max, 3\n",
    "\n",
    "def resize_px(img, px=20):\n",
    "    return img.resize((img.width*px, img.height*px), resample=Image.BOX)\n",
    "\n",
    "def transpose3d(img_array):\n",
    "    shape2 = img_array.shape\n",
    "    img_out2 = np.zeros((shape2[1], shape2[0], 3))\n",
    "    img_out2[:,:,0], img_out2[:,:,1], img_out2[:,:,2] = img_array[:,:,0].T, img_array[:,:,1].T, img_array[:,:,2].T\n",
    "    return img_out2\n",
    "    \n",
    "# pos_cls: dictionary of {'position (tuple x_y)': cluster (e.g. 3)}\n",
    "def get_img(pos_cls, size, palette):    \n",
    "    img_out = np.zeros(get_img_shape(pos_cls)) # initialize\n",
    "    \n",
    "    for x in range(img_out.shape[0]):\n",
    "        for y in range(img_out.shape[1]):\n",
    "            cluster = pos_cls.get((x,y))\n",
    "            if cluster is None:\n",
    "                img_out[x,y,0], img_out[x,y,1], img_out[x,y,2] = (.99,.99,.99)\n",
    "            else:\n",
    "                img_out[x,y,0], img_out[x,y,1], img_out[x,y,2] = palette[cluster]\n",
    "    \n",
    "    img_out = transpose3d(img_out)\n",
    "    img_out = Image.fromarray(np.uint8(img_out*255))\n",
    "    img_out =  resize_px(img_out, size)\n",
    "    \n",
    "    return img_out\n",
    "\n",
    "# Define the color palette here\n",
    "pal = {\n",
    "    'mgn2x': [\n",
    "        (sns.color_palette('autumn'))[4],  # Acellular fibrosis: Orange\n",
    "        (sns.color_palette('RdPu', 7))[6],  # Cellular fibrosis: Blue  \n",
    "        (.72, .72, .72),  # Near Normal: Brown\n",
    "        (.9, .9, .9)  ,                    # Other: Grey\n",
    "    ],\n",
    "    'mgn5x':  [\n",
    "        sns.color_palette('OrRd')[4], # Acellular fibrosis: Orange\n",
    "        sns.color_palette('YlGn',24)[12], # Cellular fibrotic IP: green\n",
    "        sns.color_palette('Blues',24)[12], # Cellular IP, NSIP: Light blue\n",
    "        (.65, .65, .65), # Complete Normal: Dark Gray\n",
    "        sns.color_palette('Blues')[5], # Lymphoid follicle: Dark Blue\n",
    "        (.9, .9, .9),                  # other: light Grey\n",
    "        sns.color_palette('RdPu',24)[8], # Edge: Pink\n",
    "        sns.color_palette('YlOrBr',24)[3], # Pale tissue: Yelllow\n",
    "    ],\n",
    "    'mgn20x_4':[\n",
    "        sns.husl_palette(24)[1], # Dense fibrosis: Orange\n",
    "        sns.husl_palette(24)[-3], # Immature fibroblasts: Pink\n",
    "        sns.color_palette('summer')[3], # Elastosis: Light green\n",
    "        sns.color_palette('YlOrBr')[0], # Fat: light Yellow\n",
    "        sns.color_palette('RdBu_r')[0], # Lymphocytes: Dark Blue\n",
    "        sns.color_palette('pink')[3], # Mucin: light Brown\n",
    "        (.9, .9, .9),                    # other: Grey\n",
    "        sns.color_palette('gist_heat')[1]  , # Respiratory epithelium: Dark Brown\n",
    "\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output file\n",
    "img_preview_dir = Path('/path/to/my/dir/maps/')\n",
    "\n",
    "# CSV file as input\n",
    "all_results = Path('/path/to/my/output/').glob('*.csv')\n",
    "\n",
    "for slide in tqdm(all_results):\n",
    "    \n",
    "    c_name = Path(slide).stem\n",
    "    epoch = c_name.split('_')[-1]\n",
    "    mgn = c_name.split('_')[-2]\n",
    "    if mgn == '4':\n",
    "        mgn = \"mgn20x_4\"\n",
    "    \n",
    "    slide_name = c_name.split('_files_')[0]\n",
    "    \n",
    "    df = pd.read_csv(slide)\n",
    "    pos_cls = {(x, y): p for x, y, p in zip(df['x'], df['y'], df['predict'])}\n",
    "    img = get_img(pos_cls, 15, pal[mgn])\n",
    "    \n",
    "    dir_to_save = img_preview_dir.joinpath(slide_name)\n",
    "    os.makedirs(dir_to_save, exist_ok=True)\n",
    "    img.save(dir_to_save.joinpath(f'{slide_name}_{mgn}.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcurate the frequency of each findings for each case (used for subsequent analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_case(df_all, mgn):\n",
    "    dataflames = []\n",
    "\n",
    "\n",
    "    for csvfile in allcsvfiles:\n",
    "        df = pd.read_csv(csvfile)\n",
    "        dataflames.append(df)\n",
    "    \n",
    "    data = pd.concat(dataflames)\n",
    "    data['predict'] = data['predict'].map(lambda x: f'{mgn}_' + str(x))\n",
    "\n",
    "\n",
    "    data = pd.crosstab(data['case'], data['predict'])\n",
    "    \n",
    "    if mgn == 'mgn5x':\n",
    "        data = data.drop('mgn5x_3', axis=1)\n",
    "    \n",
    "    data = data.apply(lambda x: x/sum(x), axis=1)\n",
    "    \n",
    "    return data\n",
    "\n",
    "allcsvfiles = data_out_dir.glob('*mgn2x.csv')\n",
    "data_2x = combine_case(allcsvfiles, 'mgn2x')\n",
    "\n",
    "allcsvfiles = data_out_dir.glob('*mgn5x.csv')\n",
    "data_5x = combine_case(allcsvfiles, 'mgn5x')\n",
    "\n",
    "allcsvfiles = data_out_dir.glob('*mgn20x_4.csv')\n",
    "data_20x = combine_case(allcsvfiles, 'mgn20x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_20x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([data_2x, data_5x, data_20x], axis=1)\n",
    "\n",
    "# drop 'other'\n",
    "df = df.drop(['mgn2x_3', 'mgn5x_5', 'mgn20x_6'], axis=1)\n",
    "\n",
    "col_rename = {\n",
    "    'mgn2x_0': 'Acellular_fibrosis_2x',\n",
    "    'mgn2x_1': 'Cellular_fibrosis_2x',\n",
    "    'mgn2x_2': 'Near_Normal_2x',\n",
    "    'mgn2x_3': 'other_2x',\n",
    "    \n",
    "    'mgn5x_0': 'Accelular_fibrosis_5x',\n",
    "    'mgn5x_1': 'Cellular_fibrotic_IP_5x',\n",
    "    'mgn5x_2': 'CellularIP_NSIP_5x',\n",
    "    'mgn5x_3': 'Complete_Normal_5x',\n",
    "    'mgn5x_4': 'Lymphoid_follicle_5x',\n",
    "    'mgn5x_5': 'other_5x',\n",
    "    'mgn5x_6': 'Edge_5x',\n",
    "    'mgn5x_7': 'Pale_5x',\n",
    "    \n",
    "    'mgn20x_0': 'Dense_fibrosis_20x',\n",
    "    'mgn20x_1': 'Immature_fibrosis_20x',\n",
    "    'mgn20x_2': 'Elastosis_20x',\n",
    "    'mgn20x_3': 'Fat_20x',\n",
    "    'mgn20x_4': 'Lymphocytes_20x',\n",
    "    'mgn20x_5': 'Mucous_20x',\n",
    "    'mgn20x_6': 'other_20x',\n",
    "    'mgn20x_7': 'Resp_epithelium_20x',\n",
    "}\n",
    "\n",
    "df = df.rename(col_rename, axis=1)\n",
    "\n",
    "df.to_csv('/path/to/my/project/features_cases.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
